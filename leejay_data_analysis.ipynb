{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e3cf8d",
   "metadata": {},
   "source": [
    "## IMPORTING THE REQUIRED LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1ffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display all columns in one line\n",
    "pd.set_option('display.max_columns', None)   # show all columns\n",
    "pd.set_option('display.width', 1000)         # set a wide width to avoid wrapping\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "df_csv = pd.read_csv('tn.movie_budgets.csv\\\\tn.movie_budgets.csv')\n",
    "\n",
    "# Load SQLite\n",
    "conn = sqlite3.connect('im.db\\im.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2920be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns:\n",
      "['id', 'release_date', 'movie', 'production_budget', 'domestic_gross', 'worldwide_gross']\n",
      "\n",
      "CSV sample data:\n",
      "   id  release_date                                        movie production_budget domestic_gross worldwide_gross\n",
      "0   1  Dec 18, 2009                                       Avatar      $425,000,000   $760,507,625  $2,776,345,279\n",
      "1   2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides      $410,600,000   $241,063,875  $1,045,663,875\n",
      "2   3   Jun 7, 2019                                 Dark Phoenix      $350,000,000    $42,762,350    $149,762,350\n",
      "3   4   May 1, 2015                      Avengers: Age of Ultron      $330,600,000   $459,005,868  $1,403,013,963\n",
      "4   5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi      $317,000,000   $620,181,382  $1,316,721,747\n"
     ]
    }
   ],
   "source": [
    "# Check CSV columns and first 5 rows\n",
    "print(\"CSV columns:\")\n",
    "print(df_csv.columns.tolist())\n",
    "\n",
    "print(\"\\nCSV sample data:\")\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d909f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite tables:\n",
      "            name\n",
      "0   movie_basics\n",
      "1      directors\n",
      "2      known_for\n",
      "3     movie_akas\n",
      "4  movie_ratings\n",
      "5        persons\n",
      "6     principals\n",
      "7        writers\n"
     ]
    }
   ],
   "source": [
    "# Check available tables\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"SQLite tables:\")\n",
    "print(tables)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5a2aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of movie_basics:\n",
      "         movie_id                                primary_title                               original_title  start_year  runtime_minutes                genres\n",
      "0       tt0063540                                    Sunghursh                                    Sunghursh        2013            175.0    Action,Crime,Drama\n",
      "1       tt0066787              One Day Before the Rainy Season                              Ashad Ka Ek Din        2019            114.0       Biography,Drama\n",
      "2       tt0069049                   The Other Side of the Wind                   The Other Side of the Wind        2018            122.0                 Drama\n",
      "3       tt0069204                              Sabse Bada Sukh                              Sabse Bada Sukh        2018              NaN          Comedy,Drama\n",
      "4       tt0100275                     The Wandering Soap Opera                        La Telenovela Errante        2017             80.0  Comedy,Drama,Fantasy\n",
      "...           ...                                          ...                                          ...         ...              ...                   ...\n",
      "146139  tt9916538                          Kuambil Lagi Hatiku                          Kuambil Lagi Hatiku        2019            123.0                 Drama\n",
      "146140  tt9916622  Rodolpho Teóphilo - O Legado de um Pioneiro  Rodolpho Teóphilo - O Legado de um Pioneiro        2015              NaN           Documentary\n",
      "146141  tt9916706                              Dankyavar Danka                              Dankyavar Danka        2013              NaN                Comedy\n",
      "146142  tt9916730                                       6 Gunn                                       6 Gunn        2017            116.0                  None\n",
      "146143  tt9916754               Chico Albuquerque - Revelações               Chico Albuquerque - Revelações        2013              NaN           Documentary\n",
      "\n",
      "[146144 rows x 6 columns]\n",
      "\n",
      "Columns in movie_basics:\n",
      "['movie_id', 'primary_title', 'original_title', 'start_year', 'runtime_minutes', 'genres']\n"
     ]
    }
   ],
   "source": [
    "# Inspect movie_basics table\n",
    "df_movie_basics = pd.read_sql_query(\"SELECT * FROM movie_basics;\", conn)\n",
    "\n",
    "print(\"\\nFirst 5 rows of movie_basics:\")\n",
    "print(df_movie_basics)\n",
    "\n",
    "print(\"\\nColumns in movie_basics:\")\n",
    "print(df_movie_basics.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381cbb5b",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a65102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in CSV:\n",
      "id                   0\n",
      "release_date         0\n",
      "movie                0\n",
      "production_budget    0\n",
      "domestic_gross       0\n",
      "worldwide_gross      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in movie_basics:\n",
      "movie_id               0\n",
      "primary_title          0\n",
      "original_title        21\n",
      "start_year             0\n",
      "runtime_minutes    31739\n",
      "genres              5408\n",
      "dtype: int64\n",
      "\n",
      "Duplicate movie titles in CSV:\n",
      "84\n",
      "\n",
      "Duplicate primary_title in movie_basics:\n",
      "10073\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values in CSV:\")\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in movie_basics:\")\n",
    "print(df_movie_basics.isnull().sum())\n",
    "\n",
    "# Check duplicates\n",
    "print(\"\\nDuplicate movie titles in CSV:\")\n",
    "print(df_csv['movie'].duplicated().sum())\n",
    "\n",
    "print(\"\\nDuplicate primary_title in movie_basics:\")\n",
    "print(df_movie_basics['primary_title'].duplicated().sum())\n",
    "\n",
    "# Clean numeric columns\n",
    "df_csv['production_budget'] = df_csv['production_budget'].replace('[\\$,]', '', regex=True)\n",
    "df_csv['production_budget'] = pd.to_numeric(df_csv['production_budget'], errors='coerce')\n",
    "\n",
    "df_csv['worldwide_gross'] = df_csv['worldwide_gross'].replace('[\\$,]', '', regex=True)\n",
    "df_csv['worldwide_gross'] = pd.to_numeric(df_csv['worldwide_gross'], errors='coerce')\n",
    "\n",
    "# Clean movie titles: strip spaces, lowercase, remove punctuation\n",
    "df_csv['movie_clean'] = ( df_csv['movie'].str.strip().str.lower().str.replace(r\"[^\\w\\s]\", \"\", regex=True))\n",
    "\n",
    "df_movie_basics['primary_title_clean'] = (df_movie_basics['primary_title'].str.strip().str.lower().str.replace(r\"[^\\w\\s]\", \"\", regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c9a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on primary_title_clean\n",
    "df_merge_primary = pd.merge(\n",
    "    df_csv,\n",
    "    df_movie_basics[['movie_id', 'primary_title', 'genres', 'start_year', 'primary_title_clean']],\n",
    "    left_on='movie_clean',\n",
    "    right_on='primary_title_clean',\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7768ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie_akas\n",
    "df_movie_akas = pd.read_sql_query(\"SELECT movie_id, title FROM movie_akas\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551699b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean movie_id type\n",
    "df_movie_basics['movie_id'] = df_movie_basics['movie_id'].astype(str)\n",
    "df_movie_akas['movie_id'] = df_movie_akas['movie_id'].astype(str)\n",
    "\n",
    "# Clean movie_akas titles\n",
    "df_movie_akas['clean_aka_title'] = (df_movie_akas['title'].str.strip().str.lower().str.replace(r\"[^\\w\\s]\", \"\", regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "988317b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched movies after primary_title merge: 3309\n"
     ]
    }
   ],
   "source": [
    "# Find unmatched movies after primary_title merge\n",
    "matched_movie_titles = df_merge_primary['movie'].unique()\n",
    "df_csv_unmatched = df_csv[~df_csv['movie'].isin(matched_movie_titles)]\n",
    "\n",
    "print(f\"Number of unmatched movies after primary_title merge: {df_csv_unmatched.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71aa801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL Merged DataFrame shape: (2595, 13)\n",
      "\n",
      "Sample merged data with genres:\n",
      "                                         movie                    genres  production_budget  worldwide_gross\n",
      "0                                       Avatar                    Horror          425000000       2776345279\n",
      "1  Pirates of the Caribbean: On Stranger Tides  Action,Adventure,Fantasy          410600000       1045663875\n",
      "2                                 Dark Phoenix   Action,Adventure,Sci-Fi          350000000        149762350\n",
      "3                      Avengers: Age of Ultron   Action,Adventure,Sci-Fi          330600000       1403013963\n",
      "4                       Avengers: Infinity War   Action,Adventure,Sci-Fi          300000000       2048134200\n",
      "\n",
      "Number of completely unmatched movies: 3103\n",
      "Example unmatched movies: ['black water transit', 'bend it like beckham', 'la guerre du feu', 'my cousin vinny', 'the thousand miles', 'seed of chucky', 'men women and children', 'artie langes beer league', 'osama', 'urbania']\n"
     ]
    }
   ],
   "source": [
    "# Merge unmatched movies with AKAS\n",
    "df_merge_akas = pd.merge(\n",
    "    df_csv_unmatched,\n",
    "    df_movie_akas[['movie_id', 'clean_aka_title']],\n",
    "    left_on='movie_clean',\n",
    "    right_on='clean_aka_title',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Bring in genres and start_year\n",
    "df_merge_akas_full = pd.merge(\n",
    "    df_merge_akas,\n",
    "    df_movie_basics[['movie_id', 'genres', 'start_year']],\n",
    "    on='movie_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Concatenate both DataFrames\n",
    "df_merged_combined = pd.concat([df_merge_primary, df_merge_akas_full], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'movie'\n",
    "df_merged_combined = df_merged_combined.drop_duplicates(subset='movie', keep='first')\n",
    "\n",
    "# Show final merged result\n",
    "print(\"\\nFINAL Merged DataFrame shape:\", df_merged_combined.shape)\n",
    "print(\"\\nSample merged data with genres:\")\n",
    "print(df_merged_combined[['movie', 'genres', 'production_budget', 'worldwide_gross']].head(5))\n",
    "\n",
    "# --- Do not re-merge on raw movie and primary_title here ---\n",
    "# That part of your code was redundant and would undo the work.\n",
    "\n",
    "# Optional: Print unmatched movie titles again if you want:\n",
    "csv_titles = set(df_csv['movie_clean'].unique())\n",
    "primary_titles = set(df_movie_basics['primary_title_clean'].unique())\n",
    "aka_titles = set(df_movie_akas['clean_aka_title'].unique())\n",
    "\n",
    "total_db_titles = primary_titles.union(aka_titles)\n",
    "\n",
    "unmatched_movies = csv_titles - total_db_titles\n",
    "print(f\"\\nNumber of completely unmatched movies: {len(unmatched_movies)}\")\n",
    "if len(unmatched_movies) > 0:\n",
    "    print(\"Example unmatched movies:\", list(unmatched_movies)[:10])\n",
    "\n",
    "# Done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b669c",
   "metadata": {},
   "source": [
    "## DATA CLEANING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c235925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres               26\n",
      "production_budget     0\n",
      "worldwide_gross       0\n",
      "dtype: int64\n",
      "Movies with missing genres: 26\n",
      "\n",
      "Movies with 0 or missing production_budget:\n",
      "Empty DataFrame\n",
      "Columns: [movie, production_budget]\n",
      "Index: []\n",
      "\n",
      "Movies with 0 or missing worldwide_gross:\n",
      "                   movie  worldwide_gross\n",
      "487               Bright                0\n",
      "516     Call of the Wild                0\n",
      "754     The Ridiculous 6                0\n",
      "755               Midway                0\n",
      "912   The Rhythm Section                0\n",
      "...                  ...              ...\n",
      "4318  The Horror Network                0\n",
      "4319   Le bonheur d'Elza                0\n",
      "4329    El rey de Najayo                0\n",
      "4331    Brooklyn Bizarre                0\n",
      "4334           Arrowhead                0\n",
      "\n",
      "[240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check missing values again in merged data\n",
    "print(df_merged_combined[['genres', 'production_budget', 'worldwide_gross']].isnull().sum())\n",
    "\n",
    "# Check how many genres are 'missing'\n",
    "missing_genres_count = df_merged_combined['genres'].isnull().sum()\n",
    "print(f\"Movies with missing genres: {missing_genres_count}\")\n",
    "\n",
    "# Check how many budgets/grosses are 0 or very small\n",
    "print(\"\\nMovies with 0 or missing production_budget:\")\n",
    "print(df_merged_combined[df_merged_combined['production_budget'] <= 0][['movie', 'production_budget']])\n",
    "\n",
    "print(\"\\nMovies with 0 or missing worldwide_gross:\")\n",
    "print(df_merged_combined[df_merged_combined['worldwide_gross'] <= 0][['movie', 'worldwide_gross']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
